%% BACKPROPAGATION CLASSIFIER function
%==========================================================================
function [J Jgrad Theta1 Theta2 Backpropdata] = Backpropagation(InputLayer, HiddenLayer, OutputLayer, ...
    Theta1, Theta2, ...
    HeartInputs, HeartGroups, lambda)
%% vectorize Theta
nn_params = [Theta1(:) Theta2(:)]; %nn_params(114x1)

%% feedforward propagation
J = nnCostFunction(InputLayer, HiddenLayer, OutputLayer, ...
    Theta1, Theta2, ...
    HeartInputs, HeartGroups, lambda);

%% random initialize weights
initial_Theta1 = randInitWeights(InputLayer, HiddenLayer); %initial_Theta1(7x14)
initial_Theta2 = randInitWeights(HiddenLayer, OutputLayer); %intial_Theta2(2x8)
initial_nn_params = [initial_Theta1(:) initialTheta2(:)]; %initial_nn_params(114x1)

%% training neural network
options = optimset('Display', 'iter', 'TolFun', 1e-8);
costFunction = @(p)nnCostFunction(InputLayer, HiddenLayer, OutputLayer, ...
    Theta1, Theta2, ...
    HeartInputs, HeartGroups, lambda);
[nn_params, cost] = fminunc(costFunction, initial_nn_params, options)

%% reshape Theta
Theta1 = reshape(nn_params(1:98), size(Theta1)); %Theta1(7x14)
Theta2 = reshape(nn_params(99:end), size(Theta2)); %Theta2(2x8)

%% gradient cost function
Jgrad = gradnnCostFunction(HeartInputs, HeartGroups, Theta1, Theta2,lambda);

%% Backpropagation data
Backpropdata = zeros(size(HeartInputs, 1), OutputLayer); %Backpropdata(140x2)
for i = 1:size(HeartInputs, 1)
    Backpropdata(i,:) = simulate(HeartInputs(i,:), Theta1, Theta2);
end

%% plot in scatter
scatter(Backpropdata(HeartGroups == 1, 1), Backpropdata(HeartGroups == 0, 1), 'DisplayName', 'Backpropdata(HeartGroups == 1,1)')




